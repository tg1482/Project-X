{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download tweepy, open the terminal on jupyter notebook and write the following command: pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_cred = dict()\n",
    "\n",
    "twitter_cred['CONSUMER_KEY'] = 'D6PekEtBw79hfFnma4sDBfhRd'\n",
    "twitter_cred['CONSUMER_SECRET'] = 'BzQGGSrqxgugqHx9eUBOBi3IFTuM24LaMzjUm9xQ4dDz13lFuq'\n",
    "twitter_cred['ACCESS_KEY'] = '990318274557693953-yF2TPznzOo4mkosJnaW0hOZoaUTehvE'\n",
    "twitter_cred['ACCESS_SECRET'] = 'CANaiTLtBi3wUfp8E2M0D25Si5B8bXBYRIebm0HIGhxUr'\n",
    "\n",
    "with open('twitter_credentials.json', 'w') as secret_info:\n",
    "    json.dump(twitter_cred, secret_info, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('twitter_credentials.json') as cred_data:\n",
    "    info = json.load(cred_data)\n",
    "consumer_key = info['CONSUMER_KEY']\n",
    "consumer_secret = info['CONSUMER_SECRET']\n",
    "access_key = info['ACCESS_KEY']\n",
    "access_secret = info['ACCESS_SECRET']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(twitter_handle):\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    tweets = []\n",
    "    \n",
    "    new_tweets = api.user_timeline(screen_name = twitter_handle, count = 200, tweet_mode=\"extended\")\n",
    "    tweets.extend(new_tweets)\n",
    "    \n",
    "    oldest_tweet = tweets[-1].id - 1\n",
    "    \n",
    "    while len(new_tweets) > 0:\n",
    "        new_tweets = api.user_timeline(screen_name = twitter_handle, count = 200, max_id = oldest_tweet, tweet_mode=\"extended\")\n",
    "    \n",
    "        print ('...%s tweets have been downloaded so far' % len(tweets))\n",
    "        \n",
    "        tweets.extend(new_tweets)\n",
    "        oldest_tweet = tweets[-1].id - 1\n",
    "    \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.full_text] for tweet in tweets]\n",
    "    \n",
    "    with open('Tweets/' + twitter_handle + '_tweets.csv', 'w', encoding = 'utf8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['id', 'created_at', 'text'])\n",
    "            writer.writerows(outtweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "politicians = [\"Mitt Romey\", \"Boris Johnson\", \"Donald Trump\", \"Bernie Sanders\", \"Joe Biden\", \"Elizabeth Warren\",\n",
    "               \"Kamala Harris\", \"Pete Buttigieg\", \"Cory Booker\", \"Beto O' Rourke\", \"Andrew Yang\", \"Ben Sasse\", \n",
    "               \"Ted Cruz\", \"Mitt Romney\", \"Mark Cuban\", \"Mike Pence\", \"Jeff Flake\"]\n",
    "\n",
    "handles = [\"MittRomey\", \"BorisJohnson\", \"realDonaldTrump\", \"BernieSanders\", \"SenSanders\", \"JoeBiden\", \"ewarren\",\n",
    "           \"SenWarren\", \"KamalaHarris\", \"SenKamalaHarris\", \"PeteButtigieg\", \"CoryBooker\", \"SenBooker\", \"BetoORourke\",\n",
    "           \"AndrewYang\", \"BenSasse\", \"TedCruz\", \"SenTedCruz\", \"MittRomney\", \"SenatorRomney\", \"mcuban\", \"mike_pence\", \n",
    "           \"VP\", \"JeffFlake\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1 tweets have been downloaded so far\n",
      "...200 tweets have been downloaded so far\n",
      "...400 tweets have been downloaded so far\n",
      "...600 tweets have been downloaded so far\n",
      "...800 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...1200 tweets have been downloaded so far\n",
      "...1399 tweets have been downloaded so far\n",
      "...1599 tweets have been downloaded so far\n",
      "...1799 tweets have been downloaded so far\n",
      "...1855 tweets have been downloaded so far\n",
      "...1 tweets have been downloaded so far\n",
      "...201 tweets have been downloaded so far\n",
      "...401 tweets have been downloaded so far\n",
      "...601 tweets have been downloaded so far\n",
      "...801 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...200 tweets have been downloaded so far\n",
      "...400 tweets have been downloaded so far\n",
      "...599 tweets have been downloaded so far\n",
      "...798 tweets have been downloaded so far\n",
      "...996 tweets have been downloaded so far\n",
      "...1196 tweets have been downloaded so far\n",
      "...1396 tweets have been downloaded so far\n",
      "...1596 tweets have been downloaded so far\n",
      "...1796 tweets have been downloaded so far\n",
      "...1996 tweets have been downloaded so far\n",
      "...2196 tweets have been downloaded so far\n",
      "...2396 tweets have been downloaded so far\n",
      "...2596 tweets have been downloaded so far\n",
      "...2796 tweets have been downloaded so far\n",
      "...2996 tweets have been downloaded so far\n",
      "...3196 tweets have been downloaded so far\n",
      "...3241 tweets have been downloaded so far\n",
      "...200 tweets have been downloaded so far\n",
      "...400 tweets have been downloaded so far\n",
      "...600 tweets have been downloaded so far\n",
      "...800 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...1200 tweets have been downloaded so far\n",
      "...1400 tweets have been downloaded so far\n",
      "...1600 tweets have been downloaded so far\n",
      "...1800 tweets have been downloaded so far\n",
      "...2000 tweets have been downloaded so far\n",
      "...2200 tweets have been downloaded so far\n",
      "...2400 tweets have been downloaded so far\n",
      "...2600 tweets have been downloaded so far\n",
      "...2800 tweets have been downloaded so far\n",
      "...3000 tweets have been downloaded so far\n",
      "...3199 tweets have been downloaded so far\n",
      "...3238 tweets have been downloaded so far\n",
      "...200 tweets have been downloaded so far\n",
      "...400 tweets have been downloaded so far\n",
      "...600 tweets have been downloaded so far\n",
      "...800 tweets have been downloaded so far\n",
      "...1000 tweets have been downloaded so far\n",
      "...1200 tweets have been downloaded so far\n",
      "...1399 tweets have been downloaded so far\n",
      "...1599 tweets have been downloaded so far\n",
      "...1799 tweets have been downloaded so far\n",
      "...1890 tweets have been downloaded so far\n"
     ]
    }
   ],
   "source": [
    "for handle in handles[0:6]:\n",
    "    get_tweets(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
